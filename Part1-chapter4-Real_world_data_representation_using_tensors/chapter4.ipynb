{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing the layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 720, 1280])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=3\n",
    "batch = torch.zeros(batch_size,3,256,256,dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '../data/p1ch4/image-cats'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1]=='.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir,filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2,0,1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[156, 152, 124,  ..., 150, 149, 158],\n",
       "          [174, 134, 165,  ..., 120, 136, 138],\n",
       "          [127, 156, 107,  ..., 131, 143, 164],\n",
       "          ...,\n",
       "          [116, 130, 129,  ..., 127, 118, 112],\n",
       "          [129, 130, 123,  ..., 115, 121, 114],\n",
       "          [129, 123, 118,  ..., 113, 121, 120]],\n",
       "\n",
       "         [[139, 135, 109,  ..., 135, 135, 147],\n",
       "          [160, 119, 149,  ..., 105, 122, 124],\n",
       "          [113, 140,  90,  ..., 118, 129, 152],\n",
       "          ...,\n",
       "          [ 99, 110, 111,  ..., 117, 108, 103],\n",
       "          [111, 111, 106,  ..., 106, 112, 105],\n",
       "          [111, 104, 102,  ..., 103, 110, 111]],\n",
       "\n",
       "         [[129, 123,  98,  ..., 131, 132, 145],\n",
       "          [155, 110, 137,  ..., 102, 119, 121],\n",
       "          [104, 132,  80,  ..., 112, 125, 146],\n",
       "          ...,\n",
       "          [ 93, 108, 105,  ..., 125, 115, 108],\n",
       "          [108, 108,  98,  ..., 110, 117, 110],\n",
       "          [107,  98,  95,  ..., 108, 115, 116]]],\n",
       "\n",
       "\n",
       "        [[[202, 193, 190,  ...,  13,  13,  12],\n",
       "          [199, 192, 189,  ...,  14,  14,  14],\n",
       "          [198, 193, 188,  ...,  12,  12,  12],\n",
       "          ...,\n",
       "          [ 93,  82,  76,  ...,  36,  36,  36],\n",
       "          [ 75,  68, 101,  ...,  36,  36,  37],\n",
       "          [ 85, 103,  90,  ...,  36,  37,  38]],\n",
       "\n",
       "         [[151, 139, 133,  ...,   9,   9,   8],\n",
       "          [151, 140, 134,  ...,  11,  11,  11],\n",
       "          [152, 143, 134,  ...,  11,  11,  11],\n",
       "          ...,\n",
       "          [ 57,  45,  39,  ...,  26,  26,  26],\n",
       "          [ 33,  26,  59,  ...,  26,  26,  27],\n",
       "          [ 40,  58,  45,  ...,  26,  27,  28]],\n",
       "\n",
       "         [[ 68,  53,  44,  ...,   6,   6,   5],\n",
       "          [ 67,  54,  44,  ...,   6,   6,   6],\n",
       "          [ 67,  56,  44,  ...,   6,   6,   6],\n",
       "          ...,\n",
       "          [ 31,  19,  12,  ...,  17,  17,  17],\n",
       "          [ 11,   2,  35,  ...,  17,  17,  18],\n",
       "          [ 19,  37,  22,  ...,  17,  18,  19]]],\n",
       "\n",
       "\n",
       "        [[[238, 238, 238,  ..., 214, 215, 215],\n",
       "          [238, 238, 238,  ..., 214, 215, 215],\n",
       "          [238, 238, 238,  ..., 214, 215, 215],\n",
       "          ...,\n",
       "          [214, 213, 212,  ..., 187, 190, 193],\n",
       "          [214, 213, 212,  ..., 186, 190, 192],\n",
       "          [214, 213, 212,  ..., 186, 190, 192]],\n",
       "\n",
       "         [[195, 195, 195,  ..., 173, 175, 175],\n",
       "          [195, 195, 195,  ..., 173, 175, 175],\n",
       "          [195, 195, 195,  ..., 173, 175, 175],\n",
       "          ...,\n",
       "          [128, 127, 126,  ..., 100, 103, 106],\n",
       "          [128, 127, 126,  ...,  99, 103, 105],\n",
       "          [128, 127, 126,  ...,  99, 103, 105]],\n",
       "\n",
       "         [[137, 137, 137,  ..., 125, 126, 126],\n",
       "          [137, 137, 137,  ..., 125, 126, 126],\n",
       "          [137, 137, 137,  ..., 125, 126, 126],\n",
       "          ...,\n",
       "          [ 79,  78,  77,  ...,  64,  68,  72],\n",
       "          [ 79,  78,  77,  ...,  64,  69,  71],\n",
       "          [ 79,  78,  77,  ...,  65,  69,  72]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:,c])\n",
    "    std = torch.std(batch[:,c])\n",
    "    batch[:,c] = (batch[:,c]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1439,  0.0730, -0.4234,  ...,  0.0375,  0.0198,  0.1794],\n",
       "          [ 0.4631, -0.2461,  0.3035,  ..., -0.4944, -0.2107, -0.1752],\n",
       "          [-0.3703,  0.1439, -0.7249,  ..., -0.2993, -0.0866,  0.2858],\n",
       "          ...,\n",
       "          [-0.5653, -0.3171, -0.3348,  ..., -0.3703, -0.5298, -0.6362],\n",
       "          [-0.3348, -0.3171, -0.4412,  ..., -0.5830, -0.4766, -0.6007],\n",
       "          [-0.3348, -0.4412, -0.5298,  ..., -0.6185, -0.4766, -0.4944]],\n",
       "\n",
       "         [[ 0.4632,  0.3874, -0.1058,  ...,  0.3874,  0.3874,  0.6150],\n",
       "          [ 0.8615,  0.0839,  0.6529,  ..., -0.1816,  0.1408,  0.1787],\n",
       "          [-0.0299,  0.4822, -0.4661,  ...,  0.0649,  0.2736,  0.7098],\n",
       "          ...,\n",
       "          [-0.2954, -0.0868, -0.0678,  ...,  0.0460, -0.1247, -0.2196],\n",
       "          [-0.0678, -0.0678, -0.1627,  ..., -0.1627, -0.0489, -0.1816],\n",
       "          [-0.0678, -0.2006, -0.2385,  ..., -0.2196, -0.0868, -0.0678]],\n",
       "\n",
       "         [[ 0.7792,  0.6573,  0.1495,  ...,  0.8198,  0.8401,  1.1041],\n",
       "          [ 1.3072,  0.3933,  0.9417,  ...,  0.2308,  0.5761,  0.6167],\n",
       "          [ 0.2714,  0.8401, -0.2161,  ...,  0.4339,  0.6979,  1.1245],\n",
       "          ...,\n",
       "          [ 0.0480,  0.3526,  0.2917,  ...,  0.6979,  0.4948,  0.3526],\n",
       "          [ 0.3526,  0.3526,  0.1495,  ...,  0.3933,  0.5354,  0.3933],\n",
       "          [ 0.3323,  0.1495,  0.0886,  ...,  0.3526,  0.4948,  0.5151]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9595,  0.7999,  0.7467,  ..., -2.3915, -2.3915, -2.4092],\n",
       "          [ 0.9063,  0.7822,  0.7290,  ..., -2.3738, -2.3738, -2.3738],\n",
       "          [ 0.8886,  0.7999,  0.7113,  ..., -2.4092, -2.4092, -2.4092],\n",
       "          ...,\n",
       "          [-0.9731, -1.1681, -1.2745,  ..., -1.9837, -1.9837, -1.9837],\n",
       "          [-1.2922, -1.4163, -0.8312,  ..., -1.9837, -1.9837, -1.9660],\n",
       "          [-1.1149, -0.7958, -1.0263,  ..., -1.9837, -1.9660, -1.9482]],\n",
       "\n",
       "         [[ 0.6908,  0.4632,  0.3494,  ..., -2.0024, -2.0024, -2.0214],\n",
       "          [ 0.6908,  0.4822,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n",
       "          [ 0.7098,  0.5391,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n",
       "          ...,\n",
       "          [-1.0920, -1.3196, -1.4334,  ..., -1.6800, -1.6800, -1.6800],\n",
       "          [-1.5472, -1.6800, -1.0541,  ..., -1.6800, -1.6800, -1.6610],\n",
       "          [-1.4144, -1.0730, -1.3196,  ..., -1.6800, -1.6610, -1.6420]],\n",
       "\n",
       "         [[-0.4598, -0.7644, -0.9472,  ..., -1.7190, -1.7190, -1.7394],\n",
       "          [-0.4801, -0.7441, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n",
       "          [-0.4801, -0.7035, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n",
       "          ...,\n",
       "          [-1.2113, -1.4550, -1.5972,  ..., -1.4956, -1.4956, -1.4956],\n",
       "          [-1.6175, -1.8003, -1.1300,  ..., -1.4956, -1.4956, -1.4753],\n",
       "          [-1.4550, -1.0894, -1.3941,  ..., -1.4956, -1.4753, -1.4550]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
       "          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
       "          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
       "          ...,\n",
       "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6936,  0.7467,  0.7999],\n",
       "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822],\n",
       "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822]],\n",
       "\n",
       "         [[ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
       "          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
       "          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
       "          ...,\n",
       "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2765, -0.2196, -0.1627],\n",
       "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816],\n",
       "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816]],\n",
       "\n",
       "         [[ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
       "          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
       "          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
       "          ...,\n",
       "          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4598, -0.3785],\n",
       "          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4395, -0.3988],\n",
       "          [-0.2364, -0.2567, -0.2770,  ..., -0.5207, -0.4395, -0.3785]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a specialized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# dir_path ='../data\\p1ch4\\volumetric-dicom\\2-LUNG 3.0  B70f-04083'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%24/99 files (24.2%51/99 files (51.5%78/99 files (78.8%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 10/99  (10.122/99  (22.237/99  (37.448/99  (48.570/99  (70.783/99  (83.891/99  (91.999/99  (100.0%)\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../data/p1ch4/volumetric-dicom/2-LUNG3.0B70f-04083\" # remove the blank between character, otherwise you will have a error\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol,0) # unsqueeze 是增加依偎，squeeze是去掉一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing tabular data\n",
    "### Using a real-world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a wine data tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "wine_path = '../data/p1ch4/tabular-wine/winequality-white.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wineq_numpy = np.loadtxt(wine_path,dtype=np.float32,delimiter=';',skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = next(csv.reader(open(wine_path),delimiter=';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_numpy.shape,col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape,wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:,:-1]\n",
    "data,data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wineq[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wineq[:,-1].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_onehot = torch.zeros(target.shape[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot.scatter_(1,target.unsqueeze(1),1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data,dim=0)\n",
    "data_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data,dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = (data-data_mean)/torch.sqrt(data_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_indexes = target<=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes.shape,bad_indexes.dtype,bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = data[bad_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = data[target<=3]\n",
    "mid_data = data[(target>3)&(target<7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = data[target>=7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_mean = torch.mean(bad_data,dim=0)\n",
    "mid_mean = torch.mean(mid_data,dim=0)\n",
    "good_mean = torch.mean(good_data,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "for i,args in enumerate(zip(col_list,bad_mean,mid_mean,good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i,*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:,6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data,total_sulfur_threshold)\n",
    "predicted_indexes.shape,predicted_indexes.dtype,predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_indexes = target>5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes.shape,actual_indexes.dtype,actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matches = torch.sum(actual_indexes&predicted_indexes).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predicted = torch.sum(predicted_indexes).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actual = torch.sum(actual_indexes).item()\n",
    "n_matches,n_matches/n_predicted,n_matches/n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
